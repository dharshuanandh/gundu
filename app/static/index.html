<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Speech Emotion Recognition</title>
    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        min-height: 100vh;
        padding: 20px;
        color: #333;
      }

      .container {
        max-width: 1200px;
        margin: 0 auto;
        background: white;
        border-radius: 16px;
        box-shadow: 0 20px 40px rgba(0,0,0,0.1);
        overflow: hidden;
      }

      .header {
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        color: white;
        padding: 30px;
        text-align: center;
      }

      .header h1 {
        font-size: 2.5rem;
        margin-bottom: 10px;
        font-weight: 600;
      }

      .header p {
        font-size: 1.1rem;
        opacity: 0.9;
      }

      .main-content {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 30px;
        padding: 30px;
      }

      .control-panel, .visualization-panel {
        background: #f8fafc;
        border-radius: 12px;
        padding: 25px;
        border: 1px solid #e2e8f0;
      }

      .control-group {
        margin-bottom: 25px;
      }

      .control-group h3 {
        color: #2d3748;
        margin-bottom: 15px;
        font-size: 1.2rem;
      }

      .button-group {
        display: flex;
        gap: 12px;
        margin-bottom: 20px;
        flex-wrap: wrap;
      }

      .btn {
        padding: 12px 24px;
        border: none;
        border-radius: 8px;
        font-size: 14px;
        font-weight: 600;
        cursor: pointer;
        transition: all 0.2s ease;
        min-width: 100px;
      }

      .btn:disabled {
        opacity: 0.5;
        cursor: not-allowed;
      }

      .btn-primary {
        background: #4299e1;
        color: white;
      }

      .btn-primary:hover:not(:disabled) {
        background: #3182ce;
        transform: translateY(-1px);
      }

      .btn-secondary {
        background: #e2e8f0;
        color: #4a5568;
      }

      .btn-secondary:hover:not(:disabled) {
        background: #cbd5e0;
      }

      .btn-danger {
        background: #e53e3e;
        color: white;
      }

      .btn-danger:hover:not(:disabled) {
        background: #c53030;
      }

      .status-indicators {
        display: flex;
        gap: 15px;
        flex-wrap: wrap;
      }

      .status-item {
        display: flex;
        align-items: center;
        gap: 8px;
        padding: 8px 12px;
        background: white;
        border-radius: 6px;
        border: 1px solid #e2e8f0;
      }

      .status-dot {
        width: 10px;
        height: 10px;
        border-radius: 50%;
      }

      .status-online { background: #48bb78; }
      .status-offline { background: #f56565; }
      .status-browser { background: #4299e1; }
      .status-backend { background: #ed8936; }

      .canvas-container {
        background: #1a202c;
        border-radius: 8px;
        padding: 20px;
        margin-bottom: 20px;
        position: relative;
      }

      #waveformCanvas {
        width: 100%;
        height: 200px;
        display: block;
        border-radius: 4px;
      }

      .emotion-display {
        background: white;
        border-radius: 8px;
        padding: 20px;
        border: 1px solid #e2e8f0;
      }

      .current-emotion {
        text-align: center;
        margin-bottom: 25px;
      }

      .emotion-label {
        font-size: 1.5rem;
        font-weight: 600;
        color: #2d3748;
        margin-bottom: 8px;
      }

      .emotion-confidence {
        font-size: 1rem;
        color: #718096;
        margin-bottom: 15px;
      }

      .confidence-bar {
        width: 100%;
        height: 8px;
        background: #e2e8f0;
        border-radius: 4px;
        overflow: hidden;
      }

      .confidence-fill {
        height: 100%;
        background: linear-gradient(90deg, #48bb78, #38a169);
        transition: width 0.3s ease;
      }

      .emotions-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
        gap: 12px;
        margin-bottom: 25px;
      }

      .emotion-item {
        background: white;
        border: 2px solid #e2e8f0;
        border-radius: 8px;
        padding: 15px;
        text-align: center;
        transition: all 0.2s ease;
      }

      .emotion-item.active {
        border-color: #4299e1;
        background: #ebf8ff;
      }

      .emotion-item h4 {
        font-size: 0.9rem;
        color: #4a5568;
        margin-bottom: 5px;
      }

      .emotion-value {
        font-size: 1.1rem;
        font-weight: 600;
        color: #2d3748;
      }

      .history-section {
        margin-top: 25px;
      }

      .history-title {
        font-size: 1.1rem;
        color: #2d3748;
        margin-bottom: 15px;
        font-weight: 600;
      }

      .history-chips {
        display: flex;
        flex-wrap: wrap;
        gap: 8px;
      }

      .history-chip {
        padding: 6px 12px;
        background: #edf2f7;
        border-radius: 20px;
        font-size: 0.85rem;
        color: #4a5568;
        border: 1px solid #cbd5e0;
      }

      .history-chip.recent {
        background: #4299e1;
        color: white;
        border-color: #4299e1;
      }

      .error-message {
        background: #fed7d7;
        color: #c53030;
        padding: 12px 16px;
        border-radius: 8px;
        border: 1px solid #feb2b2;
        margin-bottom: 20px;
        display: none;
      }

      .audio-level {
        background: #2d3748;
        border-radius: 4px;
        height: 4px;
        margin-bottom: 15px;
        overflow: hidden;
      }

      .audio-level-fill {
        height: 100%;
        background: linear-gradient(90deg, #48bb78, #ed8936, #e53e3e);
        transition: width 0.1s ease;
        width: 0%;
      }

      /* Mobile responsiveness */
      @media (max-width: 768px) {
        .main-content {
          grid-template-columns: 1fr;
          gap: 20px;
          padding: 20px;
        }

        .header {
          padding: 20px;
        }

        .header h1 {
          font-size: 2rem;
        }

        .control-panel, .visualization-panel {
          padding: 20px;
        }

        .button-group {
          justify-content: center;
        }

        .btn {
          flex: 1;
          min-width: 80px;
        }

        .status-indicators {
          justify-content: center;
        }

        .emotions-grid {
          grid-template-columns: repeat(2, 1fr);
        }
      }

      @media (max-width: 480px) {
        .header h1 {
          font-size: 1.5rem;
        }

        .emotions-grid {
          grid-template-columns: 1fr;
        }

        .button-group {
          flex-direction: column;
        }
      }

      /* Loading animation */
      .loading {
        display: inline-block;
        width: 20px;
        height: 20px;
        border: 2px solid #e2e8f0;
        border-radius: 50%;
        border-top-color: #4299e1;
        animation: spin 1s ease-in-out infinite;
        margin-left: 8px;
      }

      @keyframes spin {
        to { transform: rotate(360deg); }
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="header">
        <h1>Speech Emotion Recognition</h1>
        <p>Real-time emotion detection from audio input</p>
      </div>

      <div class="main-content">
        <div class="control-panel">
          <div class="control-group">
            <h3>Audio Controls</h3>
            <div class="button-group">
              <button id="startBtn" class="btn btn-primary">Start Recording</button>
              <button id="pauseBtn" class="btn btn-secondary" disabled>Pause</button>
              <button id="resetBtn" class="btn btn-danger" disabled>Reset</button>
            </div>
            
            <div class="audio-level">
              <div id="audioLevelFill" class="audio-level-fill"></div>
            </div>
            
            <div id="errorMessage" class="error-message"></div>
          </div>

          <div class="control-group">
            <h3>Status</h3>
            <div class="status-indicators">
              <div class="status-item">
                <div id="connectionStatus" class="status-dot status-offline"></div>
                <span>Connection</span>
              </div>
              <div class="status-item">
                <div id="inferenceStatus" class="status-dot status-backend"></div>
                <span id="inferenceText">Backend</span>
              </div>
              <div class="status-item">
                <div id="recordingStatus" class="status-dot status-offline"></div>
                <span>Recording</span>
              </div>
            </div>
          </div>
        </div>

        <div class="visualization-panel">
          <div class="canvas-container">
            <canvas id="waveformCanvas"></canvas>
          </div>

          <div class="emotion-display">
            <div class="current-emotion">
              <div id="currentEmotion" class="emotion-label">No emotion detected</div>
              <div id="currentConfidence" class="emotion-confidence">Confidence: 0%</div>
              <div class="confidence-bar">
                <div id="confidenceFill" class="confidence-fill" style="width: 0%"></div>
              </div>
            </div>

            <div class="emotions-grid">
              <div class="emotion-item" data-emotion="happy">
                <h4>Happy</h4>
                <div id="happyValue" class="emotion-value">0%</div>
              </div>
              <div class="emotion-item" data-emotion="sad">
                <h4>Sad</h4>
                <div id="sadValue" class="emotion-value">0%</div>
              </div>
              <div class="emotion-item" data-emotion="angry">
                <h4>Angry</h4>
                <div id="angryValue" class="emotion-value">0%</div>
              </div>
              <div class="emotion-item" data-emotion="neutral">
                <h4>Neutral</h4>
                <div id="neutralValue" class="emotion-value">0%</div>
              </div>
              <div class="emotion-item" data-emotion="fearful">
                <h4>Fearful</h4>
                <div id="fearfulValue" class="emotion-value">0%</div>
              </div>
              <div class="emotion-item" data-emotion="surprised">
                <h4>Surprised</h4>
                <div id="surprisedValue" class="emotion-value">0%</div>
              </div>
            </div>

            <div class="history-section">
              <div class="history-title">Emotion History</div>
              <div id="historyChips" class="history-chips"></div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <script>
      class SERController {
        constructor() {
          this.isRecording = false;
          this.isPaused = false;
          this.audioContext = null;
          this.analyser = null;
          this.dataArray = null;
          this.bufferLength = 0;
          this.mediaRecorder = null;
          this.audioChunks = [];
          this.animationId = null;
          this.emotionHistory = [];
          this.emotionQueue = [];
          this.bufferSize = 0;
          this.targetSampleRate = 16000;
          this.bufferDuration = 1500; // 1.5 seconds
          
          this.emotions = ['happy', 'sad', 'angry', 'neutral', 'fearful', 'surprised'];
          
          this.initializeCanvas();
          this.bindEvents();
          this.updateStatus();
        }

        initializeCanvas() {
          this.canvas = document.getElementById('waveformCanvas');
          this.ctx = this.canvas.getContext('2d');
          this.resizeCanvas();
          window.addEventListener('resize', () => this.resizeCanvas());
        }

        resizeCanvas() {
          const rect = this.canvas.getBoundingClientRect();
          this.canvas.width = rect.width * window.devicePixelRatio;
          this.canvas.height = rect.height * window.devicePixelRatio;
          this.ctx.scale(window.devicePixelRatio, window.devicePixelRatio);
          this.drawWaveform();
        }

        bindEvents() {
          document.getElementById('startBtn').addEventListener('click', () => this.startRecording());
          document.getElementById('pauseBtn').addEventListener('click', () => this.pauseRecording());
          document.getElementById('resetBtn').addEventListener('click', () => this.resetRecording());
        }

        async startRecording() {
          try {
            this.hideError();
            
            // Request microphone access
            const stream = await navigator.mediaDevices.getUserMedia({ 
              audio: {
                sampleRate: this.targetSampleRate,
                channelCount: 1,
                echoCancellation: true,
                noiseSuppression: true
              } 
            });

            // Initialize Audio Context
            this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
            this.analyser = this.audioContext.createAnalyser();
            this.analyser.fftSize = 2048;
            this.bufferLength = this.analyser.frequencyBinCount;
            this.dataArray = new Uint8Array(this.bufferLength);
            
            const source = this.audioContext.createMediaStreamSource(stream);
            source.connect(this.analyser);

            // Initialize MediaRecorder for audio chunks
            this.mediaRecorder = new MediaRecorder(stream, {
              mimeType: 'audio/webm;codecs=opus'
            });
            
            this.mediaRecorder.ondataavailable = (event) => {
              if (event.data.size > 0) {
                this.audioChunks.push(event.data);
                this.processAudioChunk(event.data);
              }
            };

            this.mediaRecorder.start(100); // Collect data every 100ms
            this.isRecording = true;
            this.isPaused = false;
            this.updateControls();
            this.updateStatus();
            this.startVisualization();

          } catch (error) {
            this.showError('Microphone access denied. Please enable microphone permissions and try again.');
            console.error('Error accessing microphone:', error);
          }
        }

        pauseRecording() {
          if (this.mediaRecorder && this.isRecording) {
            if (this.isPaused) {
              this.mediaRecorder.resume();
              this.isPaused = false;
              this.startVisualization();
            } else {
              this.mediaRecorder.pause();
              this.isPaused = true;
              this.stopVisualization();
            }
            this.updateControls();
          }
        }

        resetRecording() {
          this.stopVisualization();
          
          if (this.mediaRecorder) {
            this.mediaRecorder.stop();
            this.mediaRecorder = null;
          }
          
          if (this.audioContext) {
            this.audioContext.close();
            this.audioContext = null;
          }
          
          this.isRecording = false;
          this.isPaused = false;
          this.audioChunks = [];
          this.emotionQueue = [];
          this.emotionHistory = [];
          
          this.updateControls();
          this.updateStatus();
          this.updateEmotionDisplay({
            emotion: 'neutral',
            confidence: 0,
            allEmotions: {}
          });
          this.updateHistory();
          this.drawWaveform();
        }

        startVisualization() {
          const draw = () => {
            if (!this.isRecording || this.isPaused) return;
            
            this.drawWaveform();
            this.animationId = requestAnimationFrame(draw);
          };
          draw();
        }

        stopVisualization() {
          if (this.animationId) {
            cancelAnimationFrame(this.animationId);
            this.animationId = null;
          }
        }

        drawWaveform() {
          const width = this.canvas.clientWidth;
          const height = this.canvas.clientHeight;
          
          this.ctx.clearRect(0, 0, width, height);
          
          if (this.analyser && this.dataArray) {
            this.analyser.getByteTimeDomainData(this.dataArray);
            
            this.ctx.strokeStyle = '#4facfe';
            this.ctx.lineWidth = 2;
            this.ctx.beginPath();
            
            const sliceWidth = width * 1.0 / this.bufferLength;
            let x = 0;
            
            for (let i = 0; i < this.bufferLength; i++) {
              const v = this.dataArray[i] / 128.0;
              const y = v * height / 2;
              
              if (i === 0) {
                this.ctx.moveTo(x, y);
              } else {
                this.ctx.lineTo(x, y);
              }
              
              x += sliceWidth;
            }
            
            this.ctx.stroke();
            
            // Update audio level indicator
            const average = this.dataArray.reduce((a, b) => a + b) / this.dataArray.length;
            const level = Math.abs(average - 128) / 128 * 100;
            document.getElementById('audioLevelFill').style.width = level + '%';
          } else {
            // Draw baseline when no audio
            this.ctx.strokeStyle = '#2d3748';
            this.ctx.lineWidth = 1;
            this.ctx.beginPath();
            this.ctx.moveTo(0, height / 2);
            this.ctx.lineTo(width, height / 2);
            this.ctx.stroke();
          }
        }

        processAudioChunk(audioData) {
          // Convert audio blob to array buffer and then to PCM
          const reader = new FileReader();
          reader.onload = async (event) => {
            try {
              const arrayBuffer = event.target.result;
              const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
              const channelData = audioBuffer.getChannelData(0);
              
              // Add to buffer queue
              this.emotionQueue.push(Array.from(channelData));
              
              // Process when we have enough data (1.5 seconds)
              this.bufferSize += audioBuffer.duration * 1000;
              if (this.bufferSize >= this.bufferDuration) {
                await this.processEmotionInference();
                this.bufferSize = 0;
                this.emotionQueue = [];
              }
            } catch (error) {
              console.error('Error processing audio chunk:', error);
            }
          };
          reader.readAsArrayBuffer(audioData);
        }

        async processEmotionInference() {
          try {
            // Combine all buffered audio data
            const combinedAudio = this.emotionQueue.flat();
            
            // For now, generate dummy inference results
            // In a real implementation, this would send to backend or use browser-based ML
            const dummyResult = this.generateDummyEmotion();
            this.updateEmotionDisplay(dummyResult);
            
            // Add to history
            this.emotionHistory.push({
              emotion: dummyResult.emotion,
              confidence: dummyResult.confidence,
              timestamp: Date.now()
            });
            
            // Keep only last 10 entries
            if (this.emotionHistory.length > 10) {
              this.emotionHistory.shift();
            }
            
            this.updateHistory();
            
          } catch (error) {
            console.error('Error in emotion inference:', error);
            this.showError('Error processing audio for emotion detection.');
          }
        }

        generateDummyEmotion() {
          const emotions = this.emotions;
          const randomEmotion = emotions[Math.floor(Math.random() * emotions.length)];
          const confidence = Math.random() * 0.4 + 0.6; // 60-100% confidence
          
          const allEmotions = {};
          emotions.forEach(emotion => {
            if (emotion === randomEmotion) {
              allEmotions[emotion] = confidence;
            } else {
              allEmotions[emotion] = Math.random() * 0.3; // Lower confidence for other emotions
            }
          });
          
          // Normalize to 100%
          const total = Object.values(allEmotions).reduce((a, b) => a + b, 0);
          Object.keys(allEmotions).forEach(emotion => {
            allEmotions[emotion] = (allEmotions[emotion] / total) * 100;
          });
          
          return {
            emotion: randomEmotion,
            confidence: confidence * 100,
            allEmotions: allEmotions
          };
        }

        updateEmotionDisplay(result) {
          const emotionLabel = document.getElementById('currentEmotion');
          const confidenceLabel = document.getElementById('currentConfidence');
          const confidenceFill = document.getElementById('confidenceFill');
          
          emotionLabel.textContent = result.emotion.charAt(0).toUpperCase() + result.emotion.slice(1);
          confidenceLabel.textContent = `Confidence: ${result.confidence.toFixed(1)}%`;
          confidenceFill.style.width = `${result.confidence}%`;
          
          // Update individual emotion values
          Object.keys(result.allEmotions).forEach(emotion => {
            const valueElement = document.getElementById(`${emotion}Value`);
            if (valueElement) {
              valueElement.textContent = `${result.allEmotions[emotion].toFixed(1)}%`;
            }
            
            // Highlight active emotion
            const emotionItem = document.querySelector(`[data-emotion="${emotion}"]`);
            if (emotionItem) {
              emotionItem.classList.toggle('active', emotion === result.emotion);
            }
          });
        }

        updateHistory() {
          const historyContainer = document.getElementById('historyChips');
          historyContainer.innerHTML = '';
          
          this.emotionHistory.slice(-8).forEach((entry, index) => {
            const chip = document.createElement('div');
            chip.className = 'history-chip';
            if (index === this.emotionHistory.length - 1) {
              chip.classList.add('recent');
            }
            
            const time = new Date(entry.timestamp);
            chip.textContent = `${entry.emotion} (${entry.confidence.toFixed(0)}%)`;
            historyContainer.appendChild(chip);
          });
        }

        updateControls() {
          const startBtn = document.getElementById('startBtn');
          const pauseBtn = document.getElementById('pauseBtn');
          const resetBtn = document.getElementById('resetBtn');
          
          startBtn.disabled = this.isRecording;
          pauseBtn.disabled = !this.isRecording;
          resetBtn.disabled = !this.isRecording && this.emotionHistory.length === 0;
          
          if (this.isRecording) {
            pauseBtn.textContent = this.isPaused ? 'Resume' : 'Pause';
          } else {
            pauseBtn.textContent = 'Pause';
          }
        }

        updateStatus() {
          const connectionStatus = document.getElementById('connectionStatus');
          const inferenceStatus = document.getElementById('inferenceStatus');
          const recordingStatus = document.getElementById('recordingStatus');
          const inferenceText = document.getElementById('inferenceText');
          
          // Connection status (online for demo)
          connectionStatus.className = 'status-dot status-online';
          
          // Inference status (dummy backend inference for now)
          inferenceStatus.className = 'status-dot status-backend';
          inferenceText.textContent = 'Backend';
          
          // Recording status
          if (this.isRecording && !this.isPaused) {
            recordingStatus.className = 'status-dot status-online';
          } else if (this.isRecording && this.isPaused) {
            recordingStatus.className = 'status-dot status-offline';
          } else {
            recordingStatus.className = 'status-dot status-offline';
          }
        }

        showError(message) {
          const errorElement = document.getElementById('errorMessage');
          errorElement.textContent = message;
          errorElement.style.display = 'block';
        }

        hideError() {
          const errorElement = document.getElementById('errorMessage');
          errorElement.style.display = 'none';
        }
      }

      // Initialize the SER controller when the page loads
      document.addEventListener('DOMContentLoaded', () => {
        new SERController();
      });
    </script>
  </body>
</html>